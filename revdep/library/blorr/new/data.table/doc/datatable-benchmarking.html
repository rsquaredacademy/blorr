<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Benchmarking data.table</title>
<style type="text/css">
/**
 * Prism.s theme ported from highlight.js's xcode style
 */
pre code {
  padding: 1em;
}
.token.comment {
  color: #007400;
}
.token.punctuation {
  color: #999;
}
.token.tag,
.token.selector {
  color: #aa0d91;
}
.token.boolean,
.token.number,
.token.constant,
.token.symbol {
  color: #1c00cf;
}
.token.property,
.token.attr-name,
.token.string,
.token.char,
.token.builtin {
  color: #c41a16;
}
.token.inserted {
  background-color: #ccffd8;
}
.token.deleted {
  background-color: #ffebe9;
}
.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
  color: #9a6e3a;
}
.token.atrule,
.token.attr-value,
.token.keyword {
  color: #836c28;
}
.token.function,
.token.class-name {
  color: #DD4A68;
}
.token.regex,
.token.important,
.token.variable {
  color: #5c2699;
}
.token.important,
.token.bold {
  font-weight: bold;
}
.token.italic {
  font-style: italic;
}
</style>
<style type="text/css">
body {
  font-family: sans-serif;
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 1.5;
  box-sizing: border-box;
}
body, .footnotes, code { font-size: .9em; }
li li { font-size: .95em; }
*, *:before, *:after {
  box-sizing: inherit;
}
pre, img { max-width: 100%; }
pre, pre:hover {
  white-space: pre-wrap;
  word-break: break-all;
}
pre code {
  display: block;
  overflow-x: auto;
}
code { font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace; }
:not(pre) > code, code[class] { background-color: #F8F8F8; }
code.language-undefined, pre > code:not([class]) {
  background-color: inherit;
  border: 1px solid #eee;
}
table {
  margin: auto;
  border-top: 1px solid #666;
}
table thead th { border-bottom: 1px solid #ddd; }
th, td { padding: 5px; }
thead, tfoot, tr:nth-child(even) { background: #eee; }
blockquote {
  color: #666;
  margin: 0;
  padding-left: 1em;
  border-left: 0.5em solid #eee;
}
hr, .footnotes::before { border: 1px dashed #ddd; }
.frontmatter { text-align: center; }
#TOC .numbered li { list-style: none; }
#TOC .numbered { padding-left: 0; }
#TOC .numbered ul { padding-left: 1em; }
table, .body h2 { border-bottom: 1px solid #666; }
.body .appendix, .appendix ~ h2 { border-bottom-style: dashed; }
.footnote-ref a::before { content: "["; }
.footnote-ref a::after { content: "]"; }
section.footnotes::before {
  content: "";
  display: block;
  max-width: 20em;
}

@media print {
  body {
    font-size: 12pt;
    max-width: 100%;
  }
  tr, img { page-break-inside: avoid; }
}
@media only screen and (min-width: 992px) {
  pre { white-space: pre; }
}
</style>
<style type="text/css">
#TOC {
  border: 1px solid #ccc;
  border-radius: 5px;
  padding-left: 1em;
  background: #f6f6f6;
}
</style>
</head>
<body>
<div class="frontmatter">
<div class="title"><h1>Benchmarking data.table</h1></div>
<div class="author"><h2></h2></div>
<div class="date"><h3>2024-10-09</h3></div>
</div>
<div class="body">
<div id="TOC">
<ul class="numbered">
<li><a href="#fread-clear-caches"><span class="section-number">1.</span> fread: clear caches</a></li>
<li><a href="#subset-threshold-for-index-optimization-on-compound-queries"><span class="section-number">2.</span> subset: threshold for index optimization on compound queries</a></li>
<li><a href="#subset-index-aware-benchmarking"><span class="section-number">3.</span> subset: index aware benchmarking</a></li>
<li><a href="#by-reference-operations"><span class="section-number">4.</span> <em>by reference</em> operations</a></li>
<li><a href="#try-to-benchmark-atomic-processes"><span class="section-number">5.</span> try to benchmark atomic processes</a></li>
<li><a href="#avoid-class-coercion"><span class="section-number">6.</span> avoid class coercion</a></li>
<li><a href="#avoid-microbenchmark-times-100"><span class="section-number">7.</span> avoid <code>microbenchmark(..., times=100)</code></a></li>
<li><a href="#multithreaded-processing"><span class="section-number">8.</span> multithreaded processing</a></li>
<li><a href="#inside-a-loop-prefer-set-instead-of"><span class="section-number">9.</span> inside a loop prefer <code>set</code> instead of <code>:=</code></a></li>
<li><a href="#inside-a-loop-prefer-setdt-instead-of-data-table"><span class="section-number">10.</span> inside a loop prefer <code>setDT</code> instead of <code>data.table()</code></a></li>
</ul>
</div>
<style>
h2 {
    font-size: 20px;
}
</style>
<p>This document is meant to guide on measuring performance of <code>data.table</code>. Single place to document best practices and traps to avoid.</p>
<h1 id="fread-clear-caches"><span class="section-number">1.</span> fread: clear caches</h1>
<p>Ideally each <code>fread</code> call should be run in fresh session with the following commands preceding R execution. This clears OS cache file in RAM and HD cache.</p>
<pre><code class="language-sh">free -g
sudo sh -c 'echo 3 &gt;/proc/sys/vm/drop_caches'
sudo lshw -class disk
sudo hdparm -t /dev/sda
</code></pre>
<p>When comparing <code>fread</code> to non-R solutions be aware that R requires values of character columns to be added to <em>R’s global string cache</em>. This takes time when reading data but later operations benefit since the character strings have already been cached. Consequently, in addition to timing isolated tasks (such as <code>fread</code> alone), it’s a good idea to benchmark the total time of an end-to-end pipeline of tasks such as reading data, manipulating it, and producing final output.</p>
<h1 id="subset-threshold-for-index-optimization-on-compound-queries"><span class="section-number">2.</span> subset: threshold for index optimization on compound queries</h1>
<p>Index optimization for compound filter queries will be not be used when cross product of elements provided to filter on exceeds 1e4 elements.</p>
<pre><code class="language-r">DT = data.table(V1=1:10, V2=1:10, V3=1:10, V4=1:10)
setindex(DT)
v = c(1L, rep(11L, 9))
length(v)^4               # cross product of elements in filter
#[1] 10000                # &lt;= 10000
DT[V1 %in% v &amp; V2 %in% v &amp; V3 %in% v &amp; V4 %in% v, verbose=TRUE]
#Optimized subsetting with index 'V1__V2__V3__V4'
#on= matches existing index, using index
#Starting bmerge ...done in 0.000sec
#...
v = c(1L, rep(11L, 10))
length(v)^4               # cross product of elements in filter
#[1] 14641                # &gt; 10000
DT[V1 %in% v &amp; V2 %in% v &amp; V3 %in% v &amp; V4 %in% v, verbose=TRUE]
#Subsetting optimization disabled because the cross-product of RHS values exceeds 1e4, causing memory problems.
#...
</code></pre>
<h1 id="subset-index-aware-benchmarking"><span class="section-number">3.</span> subset: index aware benchmarking</h1>
<p>For convenience <code>data.table</code> automatically builds an index on fields you use to subset data. It will add some overhead to first subset on particular fields but greatly reduces time to query those columns in subsequent runs. When measuring speed, the best way is to measure index creation and query using an index separately. Having such timings it is easy to decide what is the optimal strategy for your use case.
To control usage of index use following options:</p>
<pre><code class="language-r">options(datatable.auto.index=TRUE)
options(datatable.use.index=TRUE)
</code></pre>
<ul>
<li><code>use.index=FALSE</code> will force the query not to use indices even if they exist, but existing keys are still used for optimization.</li>
<li><code>auto.index=FALSE</code> disables building index automatically when doing subset on non-indexed data, but if indices were created before this option was set, or explicitly by calling <code>setindex</code> they still will be used for optimization.</li>
</ul>
<p>Two other options control optimization globally, including use of indices:</p>
<pre><code class="language-r">options(datatable.optimize=2L)
options(datatable.optimize=3L)
</code></pre>
<p><code>options(datatable.optimize=2L)</code> will turn off optimization of subsets completely, while <code>options(datatable.optimize=3L)</code> will switch it back on.
Those options affect many more optimizations and thus should not be used when only control of indices is needed. Read more in <code>?datatable.optimize</code>.</p>
<h1 id="by-reference-operations"><span class="section-number">4.</span> <em>by reference</em> operations</h1>
<p>When benchmarking <code>set*</code> functions it only makes sense to measure the first run. These functions update their input by reference, so subsequent runs will use the already-processed <code>data.table</code>, biasing the results.</p>
<p>Protecting your <code>data.table</code> from being updated by reference operations can be achieved using <code>copy</code> or <code>data.table:::shallow</code> functions. Be aware <code>copy</code> might be very expensive as it needs to duplicate whole object. It is unlikely we want to include duplication time in time of the actual task we are benchmarking.</p>
<h1 id="try-to-benchmark-atomic-processes"><span class="section-number">5.</span> try to benchmark atomic processes</h1>
<p>If your benchmark is meant to be published it will be much more insightful if you will split it to measure time of atomic processes. This way your readers can see how much time was spent on reading data from source, cleaning, actual transformation, exporting results.
Of course if your benchmark is meant to present to present an <em>end-to-end workflow</em>, then it makes perfect sense to present the overall timing. Nevertheless, separating out timing of individual steps is useful for understanding which steps are the main bottlenecks of a workflow.
There are other cases when atomic benchmarking might not be desirable, for example when <em>reading a csv</em>, followed by <em>grouping</em>. R requires populating <em>R’s global string cache</em> which adds extra overhead when importing character data to an R session. On the other hand, the <em>global string cache</em> might speed up processes like <em>grouping</em>. In such cases when comparing R to other languages it might be useful to include total timing.</p>
<h1 id="avoid-class-coercion"><span class="section-number">6.</span> avoid class coercion</h1>
<p>Unless this is what you truly want to measure you should prepare input objects of the expected class for every tool you are benchmarking.</p>
<h1 id="avoid-microbenchmark-times-100"><span class="section-number">7.</span> avoid <code>microbenchmark(..., times=100)</code></h1>
<p>Repeating a benchmark many times usually does not give the clearest picture for data processing tools. Of course, it makes perfect sense for more atomic calculations, but this is not a good representation of the most common way these tools will actually be used, namely for data processing tasks, which consist of batches of sequentially provided transformations, each run once.
Matt once said:</p>
<blockquote>
<p>I’m very wary of benchmarks measured in anything under 1 second. Much prefer 10 seconds or more for a single run, achieved by increasing data size. A repetition count of 500 is setting off alarm bells. 3-5 runs should be enough to convince on larger data. Call overhead and time to GC affect inferences at this very small scale.</p>
</blockquote>
<p>This is very valid. The smaller time measurement is the relatively bigger noise is. Noise generated by method dispatch, package/class initialization, etc. Main focus of benchmark should be on real use case scenarios.</p>
<h1 id="multithreaded-processing"><span class="section-number">8.</span> multithreaded processing</h1>
<p>One of the main factors that is likely to impact timings is the number of threads available to your R session. In recent versions of <code>data.table</code>, some functions are parallelized.
You can control the number of threads you want to use with <code>setDTthreads</code>.</p>
<pre><code class="language-r">setDTthreads(0)    # use all available cores (default)
getDTthreads()     # check how many cores are currently used
</code></pre>
<h1 id="inside-a-loop-prefer-set-instead-of"><span class="section-number">9.</span> inside a loop prefer <code>set</code> instead of <code>:=</code></h1>
<p>Unless you are utilizing index when doing <em>sub-assign by reference</em> you should prefer <code>set</code> function which does not impose overhead of <code>[.data.table</code> method call.</p>
<pre><code class="language-r">DT = data.table(a=3:1, b=letters[1:3])
setindex(DT, a)

# for (...) {                 # imagine loop here

  DT[a==2L, b := &quot;z&quot;]         # sub-assign by reference, uses index
  DT[, d := &quot;z&quot;]              # not sub-assign by reference, not uses index and adds overhead of `[.data.table`
  set(DT, j=&quot;d&quot;, value=&quot;z&quot;)   # no `[.data.table` overhead, but no index yet, till #1196

# }
</code></pre>
<h1 id="inside-a-loop-prefer-setdt-instead-of-data-table"><span class="section-number">10.</span> inside a loop prefer <code>setDT</code> instead of <code>data.table()</code></h1>
<p>As of now <code>data.table()</code> has an overhead, thus inside loops it is preferred to use <code>as.data.table()</code> or <code>setDT()</code> on a valid list.</p>
</div>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js" defer></script>
</body>
</html>
